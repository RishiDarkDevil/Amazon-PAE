{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c53a9a61",
   "metadata": {},
   "source": [
    "## Loading Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea84f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:04:20.760267Z",
     "iopub.status.busy": "2023-05-27T09:04:20.759935Z",
     "iopub.status.idle": "2023-05-27T09:04:35.823040Z",
     "shell.execute_reply": "2023-05-27T09:04:35.822117Z",
     "shell.execute_reply.started": "2023-05-27T09:04:20.760238Z"
    }
   },
   "outputs": [],
   "source": [
    "# general\n",
    "import re\n",
    "import gc\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# HTML parsing\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# chunker\n",
    "import torch\n",
    "from torch import cuda\n",
    "# import flair\n",
    "# from flair.data import Sentence\n",
    "# from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8106b16e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811fc941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:04:35.825283Z",
     "iopub.status.busy": "2023-05-27T09:04:35.824416Z",
     "iopub.status.idle": "2023-05-27T09:05:15.433126Z",
     "shell.execute_reply": "2023-05-27T09:05:15.432201Z",
     "shell.execute_reply.started": "2023-05-27T09:04:35.825248Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2023 Data\n",
    "data = pd.read_csv('../data/2023/train-v3.csv', usecols=['DESCRIPTION'])\n",
    "# data = pd.read_csv('../data/2023/test-v2.csv')\n",
    "\n",
    "# 2021 Data\n",
    "# data = pd.read_csv('../data/2021/train-v2.csv')\n",
    "# data = pd.read_csv('../data/2021/test-v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb6002f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:05:15.436251Z",
     "iopub.status.busy": "2023-05-27T09:05:15.435867Z",
     "iopub.status.idle": "2023-05-27T09:05:16.138018Z",
     "shell.execute_reply": "2023-05-27T09:05:16.137092Z",
     "shell.execute_reply.started": "2023-05-27T09:05:15.436218Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3130e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:05:16.140229Z",
     "iopub.status.busy": "2023-05-27T09:05:16.139288Z",
     "iopub.status.idle": "2023-05-27T09:05:16.842923Z",
     "shell.execute_reply": "2023-05-27T09:05:16.841954Z",
     "shell.execute_reply.started": "2023-05-27T09:05:16.140194Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[~data.DESCRIPTION.isin([''])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64f4240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:05:16.844680Z",
     "iopub.status.busy": "2023-05-27T09:05:16.844340Z",
     "iopub.status.idle": "2023-05-27T09:05:16.861418Z",
     "shell.execute_reply": "2023-05-27T09:05:16.860443Z",
     "shell.execute_reply.started": "2023-05-27T09:05:16.844647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Specifications : Color : Red , Material : Alum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AISHAH Women ' s Lycra Cotton Ankel Leggings ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HINS Brings you the most Elegant Looking Pot w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aluminum Foil Stickers-good kitchen helper for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Transform your home , workplace or hotel room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249688</th>\n",
       "      <td>Welcome to the wonderfully Wicked World of Aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249689</th>\n",
       "      <td>This extra long Tall t-Shirt will be your favo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249694</th>\n",
       "      <td>[ Brand ] : XVIEONR [ Product name ] : Fashion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249695</th>\n",
       "      <td>Wall Clocks Are Very Attractive In Looks And E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249697</th>\n",
       "      <td>Skyjacker C7360SP Component Box For PN [ C7360...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1092187 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               DESCRIPTION\n",
       "2        Specifications : Color : Red , Material : Alum...\n",
       "3        AISHAH Women ' s Lycra Cotton Ankel Leggings ....\n",
       "5        HINS Brings you the most Elegant Looking Pot w...\n",
       "7        Aluminum Foil Stickers-good kitchen helper for...\n",
       "9        Transform your home , workplace or hotel room ...\n",
       "...                                                    ...\n",
       "2249688  Welcome to the wonderfully Wicked World of Aut...\n",
       "2249689  This extra long Tall t-Shirt will be your favo...\n",
       "2249694  [ Brand ] : XVIEONR [ Product name ] : Fashion...\n",
       "2249695  Wall Clocks Are Very Attractive In Looks And E...\n",
       "2249697  Skyjacker C7360SP Component Box For PN [ C7360...\n",
       "\n",
       "[1092187 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae106f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idxs = data.index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea10a2",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b94b42d",
   "metadata": {},
   "source": [
    "Since, we have lot of text data, capturing the entire graph between all the tokens would be difficult (time consuming). So, let's chunk the text into sections to capture the local information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13b2f6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:05:16.863284Z",
     "iopub.status.busy": "2023-05-27T09:05:16.862931Z",
     "iopub.status.idle": "2023-05-27T09:05:16.867816Z",
     "shell.execute_reply": "2023-05-27T09:05:16.866741Z",
     "shell.execute_reply.started": "2023-05-27T09:05:16.863254Z"
    }
   },
   "outputs": [],
   "source": [
    "flair.device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8236212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:05:16.869759Z",
     "iopub.status.busy": "2023-05-27T09:05:16.869174Z",
     "iopub.status.idle": "2023-05-27T09:05:16.880462Z",
     "shell.execute_reply": "2023-05-27T09:05:16.879474Z",
     "shell.execute_reply.started": "2023-05-27T09:05:16.869727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c32d168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:05:16.882266Z",
     "iopub.status.busy": "2023-05-27T09:05:16.881563Z",
     "iopub.status.idle": "2023-05-27T09:05:25.443498Z",
     "shell.execute_reply": "2023-05-27T09:05:25.442528Z",
     "shell.execute_reply.started": "2023-05-27T09:05:16.882234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789af0108c4046e2981672017c75d8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/72.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 09:05:25,344 SequenceTagger predicts: Dictionary with 47 tags: O, S-NP, B-NP, E-NP, I-NP, S-VP, B-VP, E-VP, I-VP, S-PP, B-PP, E-PP, I-PP, S-ADVP, B-ADVP, E-ADVP, I-ADVP, S-SBAR, B-SBAR, E-SBAR, I-SBAR, S-ADJP, B-ADJP, E-ADJP, I-ADJP, S-PRT, B-PRT, E-PRT, I-PRT, S-CONJP, B-CONJP, E-CONJP, I-CONJP, S-INTJ, B-INTJ, E-INTJ, I-INTJ, S-LST, B-LST, E-LST, I-LST, S-UCP, B-UCP, E-UCP, I-UCP, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/chunk-english-fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc4ca275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:05:25.447080Z",
     "iopub.status.busy": "2023-05-27T09:05:25.446673Z",
     "iopub.status.idle": "2023-05-27T09:05:25.452134Z",
     "shell.execute_reply": "2023-05-27T09:05:25.451207Z",
     "shell.execute_reply.started": "2023-05-27T09:05:25.447044Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimize_gpu():\n",
    "  \"\"\"\n",
    "  Frees up GPU to help reduce memory leak\n",
    "  Reset Already occupied Memory and Cache\n",
    "  \"\"\"\n",
    "  torch.cuda.reset_max_memory_allocated()\n",
    "  \n",
    "  torch.cuda.reset_max_memory_cached()\n",
    "  \n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "  # Garbage Collection\n",
    "  gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927a3ac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:05:25.454105Z",
     "iopub.status.busy": "2023-05-27T09:05:25.453765Z",
     "iopub.status.idle": "2023-05-27T09:05:25.462494Z",
     "shell.execute_reply": "2023-05-27T09:05:25.461612Z",
     "shell.execute_reply.started": "2023-05-27T09:05:25.454074Z"
    }
   },
   "outputs": [],
   "source": [
    "os.mkdir('description-chunked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b526519a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:06:18.181367Z",
     "iopub.status.busy": "2023-05-27T09:06:18.180626Z",
     "iopub.status.idle": "2023-05-27T09:06:18.188390Z",
     "shell.execute_reply": "2023-05-27T09:06:18.187335Z",
     "shell.execute_reply.started": "2023-05-27T09:06:18.181335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0] // 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "873b0191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T09:07:19.619271Z",
     "iopub.status.busy": "2023-05-27T09:07:19.618883Z",
     "iopub.status.idle": "2023-05-27T09:07:58.948169Z",
     "shell.execute_reply": "2023-05-27T09:07:58.947218Z",
     "shell.execute_reply.started": "2023-05-27T09:07:19.619238Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Batch inference:   0%|          | 0/51 [00:00<?, ?it/s]\u001b[A\n",
      "Batch inference:   2%|▏         | 1/51 [00:05<04:48,  5.76s/it]\u001b[A\n",
      "Batch inference:   4%|▍         | 2/51 [00:07<02:50,  3.49s/it]\u001b[A\n",
      "Batch inference:   6%|▌         | 3/51 [00:09<02:00,  2.51s/it]\u001b[A\n",
      "Batch inference:   8%|▊         | 4/51 [00:09<01:29,  1.91s/it]\u001b[A\n",
      "Batch inference:  10%|▉         | 5/51 [00:10<01:10,  1.53s/it]\u001b[A\n",
      "Batch inference:  12%|█▏        | 6/51 [00:11<00:57,  1.29s/it]\u001b[A\n",
      "Batch inference:  14%|█▎        | 7/51 [00:13<00:57,  1.31s/it]\u001b[A\n",
      "Batch inference:  16%|█▌        | 8/51 [00:13<00:48,  1.12s/it]\u001b[A\n",
      "Batch inference:  18%|█▊        | 9/51 [00:14<00:42,  1.01s/it]\u001b[A\n",
      "Batch inference:  20%|█▉        | 10/51 [00:15<00:36,  1.11it/s]\u001b[A\n",
      "Batch inference:  22%|██▏       | 11/51 [00:15<00:33,  1.21it/s]\u001b[A\n",
      "Batch inference:  24%|██▎       | 12/51 [00:16<00:29,  1.31it/s]\u001b[A\n",
      "Batch inference:  25%|██▌       | 13/51 [00:17<00:26,  1.41it/s]\u001b[A\n",
      "Batch inference:  27%|██▋       | 14/51 [00:17<00:24,  1.49it/s]\u001b[A\n",
      "Batch inference:  29%|██▉       | 15/51 [00:18<00:22,  1.58it/s]\u001b[A\n",
      "Batch inference:  31%|███▏      | 16/51 [00:19<00:28,  1.25it/s]\u001b[A\n",
      "Batch inference:  33%|███▎      | 17/51 [00:19<00:24,  1.39it/s]\u001b[A\n",
      "Batch inference:  35%|███▌      | 18/51 [00:20<00:21,  1.51it/s]\u001b[A\n",
      "Batch inference:  37%|███▋      | 19/51 [00:20<00:19,  1.65it/s]\u001b[A\n",
      "Batch inference:  39%|███▉      | 20/51 [00:21<00:17,  1.76it/s]\u001b[A\n",
      "Batch inference:  41%|████      | 21/51 [00:21<00:16,  1.86it/s]\u001b[A\n",
      "Batch inference:  43%|████▎     | 22/51 [00:22<00:14,  1.95it/s]\u001b[A\n",
      "Batch inference:  45%|████▌     | 23/51 [00:22<00:13,  2.03it/s]\u001b[A\n",
      "Batch inference:  47%|████▋     | 24/51 [00:23<00:12,  2.11it/s]\u001b[A\n",
      "Batch inference:  49%|████▉     | 25/51 [00:23<00:11,  2.18it/s]\u001b[A\n",
      "Batch inference:  51%|█████     | 26/51 [00:24<00:11,  2.23it/s]\u001b[A\n",
      "Batch inference:  53%|█████▎    | 27/51 [00:24<00:10,  2.28it/s]\u001b[A\n",
      "Batch inference:  55%|█████▍    | 28/51 [00:24<00:09,  2.37it/s]\u001b[A\n",
      "Batch inference:  57%|█████▋    | 29/51 [00:25<00:09,  2.27it/s]\u001b[A\n",
      "Batch inference:  59%|█████▉    | 30/51 [00:25<00:08,  2.38it/s]\u001b[A\n",
      "Batch inference:  61%|██████    | 31/51 [00:26<00:12,  1.58it/s]\u001b[A\n",
      "Batch inference:  63%|██████▎   | 32/51 [00:27<00:10,  1.81it/s]\u001b[A\n",
      "Batch inference:  65%|██████▍   | 33/51 [00:27<00:08,  2.03it/s]\u001b[A\n",
      "Batch inference:  67%|██████▋   | 34/51 [00:27<00:07,  2.23it/s]\u001b[A\n",
      "Batch inference:  69%|██████▊   | 35/51 [00:28<00:06,  2.43it/s]\u001b[A\n",
      "Batch inference:  71%|███████   | 36/51 [00:28<00:05,  2.59it/s]\u001b[A\n",
      "Batch inference:  73%|███████▎  | 37/51 [00:28<00:05,  2.73it/s]\u001b[A\n",
      "Batch inference:  75%|███████▍  | 38/51 [00:29<00:04,  2.85it/s]\u001b[A\n",
      "Batch inference:  76%|███████▋  | 39/51 [00:29<00:04,  2.94it/s]\u001b[A\n",
      "Batch inference:  78%|███████▊  | 40/51 [00:29<00:03,  3.10it/s]\u001b[A\n",
      "Batch inference:  80%|████████  | 41/51 [00:30<00:03,  3.19it/s]\u001b[A\n",
      "Batch inference:  82%|████████▏ | 42/51 [00:30<00:02,  3.34it/s]\u001b[A\n",
      "Batch inference:  84%|████████▍ | 43/51 [00:30<00:02,  3.48it/s]\u001b[A\n",
      "Batch inference:  86%|████████▋ | 44/51 [00:30<00:01,  3.68it/s]\u001b[A\n",
      "Batch inference:  88%|████████▊ | 45/51 [00:31<00:01,  3.86it/s]\u001b[A\n",
      "Batch inference:  90%|█████████ | 46/51 [00:31<00:01,  4.07it/s]\u001b[A\n",
      "Batch inference:  92%|█████████▏| 47/51 [00:31<00:00,  4.29it/s]\u001b[A\n",
      "Batch inference:  94%|█████████▍| 48/51 [00:31<00:00,  4.59it/s]\u001b[A\n",
      "Batch inference:  96%|█████████▌| 49/51 [00:31<00:00,  4.83it/s]\u001b[A\n",
      "Batch inference:  98%|█████████▊| 50/51 [00:31<00:00,  5.42it/s]\u001b[A\n",
      "Batch inference: 100%|██████████| 51/51 [00:32<00:00,  1.59it/s]\u001b[A\n",
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:329: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:39<00:00, 39.31s/it]\n"
     ]
    }
   ],
   "source": [
    "PRODUCT_AT_ONCE = 10000\n",
    "LAST_CRASHED = 109\n",
    "file_no = LAST_CRASHED+1\n",
    "\n",
    "for i in tqdm(range(LAST_CRASHED, (data.shape[0] // PRODUCT_AT_ONCE)+1)):\n",
    "# for i in tqdm(range(1)):\n",
    "  # make product sentences\n",
    "  sentences = [[Sentence(sent) for sent in data.iloc[k,0].split(' . ')]\n",
    "               for k in range(i*PRODUCT_AT_ONCE, min((i+1)*PRODUCT_AT_ONCE, data.shape[0]))]\n",
    "    \n",
    "  # number of bps per product\n",
    "  len_sentences = [\n",
    "    len(bp) for bp in sentences\n",
    "  ]\n",
    "  \n",
    "  cut_offs = np.cumsum([0] + len_sentences)\n",
    "  \n",
    "  # unrolling sentences\n",
    "  \n",
    "  sentences = [bp for bps in sentences for bp in bps]\n",
    "  \n",
    "  max_toks = max([len(sent.text.split(' ')) for sent in sentences])\n",
    "  \n",
    "  if max_toks >= 2000:\n",
    "    bs = 100\n",
    "  \n",
    "  elif max_toks >= 1000:\n",
    "    bs = 200\n",
    "  \n",
    "  else:\n",
    "    bs = 250\n",
    "\n",
    "  # predict chunk tags\n",
    "  tagger.predict(sentences, verbose=True, mini_batch_size=bs)\n",
    "  \n",
    "  processed_descs = list()\n",
    "  \n",
    "  # print predicted chunk spans\n",
    "  # store predicted NER spans\n",
    "  for p in range(len(cut_offs)-1):\n",
    "    \n",
    "    processed_desc = list()\n",
    "    \n",
    "    for sentence in sentences[cut_offs[p]: cut_offs[p+1]]:\n",
    "      \n",
    "      processed_sent = list()\n",
    "      \n",
    "      # iterate over entities and print\n",
    "      \n",
    "      for entity in sentence.get_spans('np'):\n",
    "        \n",
    "        processed_sent.append((entity.text, entity.tag))\n",
    "    \n",
    "      processed_desc.append(processed_sent)\n",
    "    \n",
    "    processed_descs.append(processed_desc)\n",
    "  \n",
    "  with open(f'/kaggle/working/description-chunked/{file_no}.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_descs, f)\n",
    "  \n",
    "  file_no += 1\n",
    "  \n",
    "  optimize_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4d7dd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 110/110 [00:42<00:00,  2.60it/s]\n"
     ]
    }
   ],
   "source": [
    "chunked_descs = [pickle.load(open(f'../data/2023/temp-descs/{k+1}.pkl', 'rb')) for k in tqdm(range(110))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38e96d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 110/110 [00:05<00:00, 20.71it/s]\n"
     ]
    }
   ],
   "source": [
    "chunked_descs = [chunk for chunk_desc in tqdm(chunked_descs) for chunk in chunk_desc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6dfb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/2023/temp-descs/chunked-train-descs-2023.pkl', 'wb') as f:\n",
    "  pickle.dump(chunked_descs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5901a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
